{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cfe0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LightGBM ####\n",
    "# 모델 성능 up 모델 학습시간 down\n",
    "# 반복적인 iteration때 병목 현상이 나타나면 여러 case를 테스트하기 어려운데 그 부분을 해결해줌\n",
    "# + stacking 으로 모델 성능을 향상시킬 수 있음.\n",
    "\n",
    "# leaf-wise 방식을 씀 \n",
    "    # 한쪽으로 치우치기 때문에 overfitting되기 쉬움. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b649bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LightGBM 주요 특징 ####\n",
    "# 1. Histogram기반 feature binning\n",
    "    # 연속형 피처들을 특정한 개수의 Bin으로 할당하여 개별 피처들의 범위를 급격히 줄임\n",
    "    # ==> 수행 시간 줄임\n",
    "# 2. boosting시 GBDT외에 GOSS, DART 방식 제공\n",
    "    # GOSS: Gradient값이 큰 값에 대해서만 선택적으로 필터링하여 반복적 재학습\n",
    "        # : 작으면 이미 진행되었다고 가정\n",
    "        # : 수행 시간을 줄였지만 모델 성능 향상에는 의미 (gradient가 작은 부분에 대해서는 학습을 하지 않았기 때문)\n",
    "    # DART: 자잘한 조건을 맞추기 위해 트리가 세분화 되는 것을 방지\n",
    "# 3. overfitting을 극복하기 위한 hyper parameters\n",
    "\n",
    "#### LightGBM type ####\n",
    "# gbdt(default), goss, dart, rt\n",
    "# ==> 직접 수행해봐야 어떤 것이 가장 좋은지 알 수 있음. \n",
    "\n",
    "#### 하이퍼 파라미터 ####\n",
    "# why? LightGBM의 경우 leaf-wise 방식을 쓰기 때문에 overfitting 되기 쉬움\n",
    "# 때문에 하이퍼 파라미터 튜닝을 통해 이를 방지하고자 함. \n",
    "\n",
    "# 종류:\n",
    "    # n_estimators\n",
    "    # learning_rate\n",
    "    # (과적합을 방지하기 위해 아래 파라미터 사용)\n",
    "    # max_depth : 트리의 깊이 (=> 보통 피처의 개수가 많으면 max_depth를 10~16으로 둔다고 함.)\n",
    "    # num_leaves : leaf nodes의 개수\n",
    "    # subsample : 레코드 개수, 데이터를 샘플링하는 비율 지정\n",
    "    # colsample_bytree : 피처(컬럼) 개수, 트리 생성에 필요한 피처를 임의로 샘플링\n",
    "    # min_child_samples : 리프 노드의 최소 데이터 개수\n",
    "    # reg_lambda : L2 규제\n",
    "    # reg_alpha : L1 규제 (L1을 조절하는 것이 L2를 조절하는 것보다 성능이 더 좋다는 말이 있음.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95023a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 하이퍼 파라미터 튜닝 방법 ####\n",
    "# GridSearchCV, Randomized Search\n",
    "    # 둘은 운빨에 의존함\n",
    "    # 수행시간이 너무 오래 걸림. \n",
    "    # 어느정도 최적화된 하이퍼 파리미터를 활용하여 최적화를 수행하지 않음. \n",
    "    \n",
    "# Bayesian Optimazation (-> 그 이후에 어느 정도의 수동 튜닝.)\n",
    "# (데이터를 받으면 사후 확률 개선 가능)\n",
    "    # 점점 많은 값을 받아 수행하면서 사후분포가 점점 개선되고 함수 반환 값을 최대(최소)가 되는\n",
    "    # 입력 파라미터 영역을 보다 확실하게 찾게 됨.\n",
    "    \n",
    "# 하이퍼 파라미터 튜닝\n",
    "    # 트리구조\n",
    "        # max_depth\n",
    "        # num_leaves\n",
    "        # min_child_samples\n",
    "        # min_child_weight : 균일도\n",
    "    # 샘플링 비율\n",
    "        # subsample\n",
    "        # colsample_bytree\n",
    "    # 손실함수 규제\n",
    "        # reg_lambda\n",
    "        # reg_alpha\n",
    "    # feature histogram\n",
    "        # max_bin\n",
    "        \n",
    "# 순서\n",
    "    # 1. 함수 입력 인자 범위 설정 : baysesian_params = {}\n",
    "    # 2. 함수 선언\n",
    "    # 3. 베이지안 객체에 넣어줌\n",
    "    \n",
    "# 유의사항 \n",
    "    # 1. 언제나 최고의 최적화된 파라미터 추출 X\n",
    "    # 2. 사전에 유일한 파라미터의 범위 제약\n",
    "    # 3. 가능하면 CV로 함수 결과 반환. But, 최적 하이퍼 파라미터 X\n",
    "    # 4. 너무 하이퍼 파라미터 튜닝에 의존 X\n",
    "    # ==> 하아퍼 파라미터 튜닝은 1~2% 좋아지면 좋아진 것! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e3f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# parameter 설정 \n",
    "# parameter는 지속적으로 반복하다보면 범위가 잡힘\n",
    "    # 수업에서는 선생님께서 자신만의 파라미터를 가지고 있는 분들도 있다고 하심. \n",
    "    \n",
    "bayesian_params = {\n",
    "    'max_depth': (6, 16), # max_depth는 보통 이 정도로 설정하면 될 것 같음. \n",
    "    'num_leaves': (24, 64), \n",
    "    'min_child_samples': (10, 200), \n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0),\n",
    "    'max_bin':(10, 500),\n",
    "    'reg_lambda':(0.001, 10),\n",
    "    'reg_alpha': (0.01, 50) \n",
    "}\n",
    "\n",
    "# 함수 선언 : roc_auc_score을 반환해줘야 함. \n",
    "def lgb_roc_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
    "                colsample_bytree,max_bin, reg_lambda, reg_alpha):\n",
    "    params = {\n",
    "        \"n_estimators\":500, \"learning_rate\":0.02,\n",
    "        'max_depth': int(round(max_depth)), #  호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경 \n",
    "        'num_leaves': int(round(num_leaves)), \n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample': max(min(subsample, 1), 0), \n",
    "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
    "        'max_bin':  max(int(round(max_bin)),10),\n",
    "        'reg_lambda': max(reg_lambda,0),\n",
    "        'reg_alpha': max(reg_alpha, 0)\n",
    "    }\n",
    "    lgb_model = LGBMClassifier(**params)\n",
    "    lgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "                  eval_metric= 'auc', verbose= 100, # verbose는 단지 몇 번마다 결괏값을 출력해줌. \n",
    "                  early_stopping_rounds= 100)\n",
    "    \n",
    "    valid_proba = lgb_model.predict_proba(valid_x)[:, 1]\n",
    "    roc_auc = roc_auc_score(valid_y, valid_proba)\n",
    "    \n",
    "    return roc_auc  \n",
    "\n",
    "# iteration 수행 ==> 약 50분이 걸린다고 하심\n",
    "lgbBO = BayesianOptimization(f = lgb_roc_eval, \n",
    "                             pbounds = bayesian_params,\n",
    "                             random_state=0,)\n",
    "lgbBO.maximize(init_points=5, n_iter=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8fb1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 iteration 반환값을 가지고 있는 .res\n",
    "lgBO.res \n",
    "\n",
    "# dictionary에 있는 target값을 모두 추출\n",
    "target_list = []\n",
    "for result in lgbBO.res:\n",
    "    target = result['target']\n",
    "    target_list.append(target)\n",
    "print(target_list)\n",
    "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
    "print('maximum target index:', np.argmax(np.array(target_list)))\n",
    "\n",
    "# 가장 큰 target값을 가지고 있는 index값을 기준으로 parameter 추출\n",
    "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
    "print(max_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650fa625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 파라미터 결괏값을 가지고 모델 학습\n",
    "def train_apps_all(apps_all_train):\n",
    "    ftr_app = apps_all_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
    "    target_app = apps_all_train['TARGET']\n",
    "\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(ftr_app, target_app, test_size=0.3, random_state=2020)\n",
    "    print('train shape:', train_x.shape, 'valid shape:', valid_x.shape)\n",
    "    clf = LGBMClassifier(\n",
    "                nthread=4,\n",
    "                n_estimators=1000,\n",
    "                learning_rate=0.02,\n",
    "                max_depth = 13,\n",
    "                num_leaves=57,\n",
    "                colsample_bytree=0.638,\n",
    "                subsample=0.682,\n",
    "                max_bin=435,\n",
    "                reg_alpha=0.936,\n",
    "                reg_lambda=4.533,\n",
    "                min_child_weight=25,\n",
    "                min_child_samples=166,\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                )\n",
    "\n",
    "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric= 'auc', verbose= 100, \n",
    "            early_stopping_rounds= 100)\n",
    "    \n",
    "    return clf\n",
    "\n",
    "# 이후 예측 및 평가 \n",
    "preds = clf.predict_proba(apps_all_test.drop('SK_ID_CURR', axis=1))[:, 1 ]\n",
    "apps_all_test['TARGET'] = preds\n",
    "apps_all_test[['SK_ID_CURR', 'TARGET']].to_csv('prev_baseline_tuning_01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac93bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유의사항\n",
    "# CV가 무조건 좋은 성능을 나타내는 것은 아님 \n",
    "# 실행해보면서 가장 좋은 것 찾아내기. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff5d0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b70c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5456c5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f2f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39eeb67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550309e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20156a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee8ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e67e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc1d077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da97b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18abb122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cdf67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6088a089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
